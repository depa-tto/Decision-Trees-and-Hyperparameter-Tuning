{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # type: ignore\n",
    "import pandas as pd # type: ignore\n",
    "import matplotlib.pyplot as plt # type: ignore\n",
    "import seaborn as sns # type: ignore\n",
    "import random\n",
    "from pprint import pprint\n",
    "import plotly.express as px # type: ignore\n",
    "from tabulate import tabulate # type: ignore\n",
    "from sklearn.metrics import confusion_matrix # type: ignore\n",
    "from sklearn.metrics import accuracy_score # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and preparation of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/adepa/OneDrive/Desktop/MushroomDataset/secondary_data.csv\"\n",
    "\n",
    "df = pd.read_csv(path, sep = ';')\n",
    "\n",
    "df = df.rename(columns={\"class\": \"label\"})\n",
    "temp_cols = df.columns.tolist()\n",
    "new_cols = temp_cols[1:] + temp_cols[0:1]\n",
    "df = df[new_cols]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_counts = df.isnull().sum()\n",
    "\n",
    "table = [[col, na_counts[col]] for col in na_counts.index]\n",
    "col_names = [\"Features\", \"NA\"]\n",
    "\n",
    "print(tabulate(table, headers=col_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['gill-spacing','stem-root', 'stem-surface', 'veil-type', 'veil-color', 'spore-print-color'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cap-shape'] = df['cap-shape'].map({'b':'bell', 'c':'conical', 'x':'convex', 'f':'flat', 's':'sunken', 'p':'spherical', 'o':'others'})\n",
    "df['cap-surface'] = df['cap-surface'].map({'i':'fibrous', 'g':'grooves', 'y':'scaly', 's':'smooth', 'h':'shiny', 'l':'leathery', 'k':'silky', 't':'sticky', 'w':'wrinkled', 'e':'fleshy', 'd': 'dry'})\n",
    "df['cap-color'] = df['cap-color'].map({'n':'brown', 'b':'buff', 'g':'gray', 'r':'green', 'p':'pink', 'u':'purple', 'e':'red', 'w':'white', 'y':'yellow', 'l':'blue', 'o':'orange', 'k':'black'})\n",
    "df['does-bruise-or-bleed'] = df['does-bruise-or-bleed'].map({'t':'bruises-bleedin', 'f':'not-bruises-bleedin'})\n",
    "df['gill-attachment'] = df['gill-attachment'].map({'a':'bell', 'x':'conical', 'd':'convex', 'e':'flat', 's':'sunken', 'p':'spherical', 'f':'none', '?':'none'})\n",
    "df['gill-color'] = df['gill-color'].map({'n':'brown', 'b':'buff', 'g':'gray', 'r':'green', 'p':'pink', 'u':'purple', 'e':'red', 'w':'white', 'y':'yellow', 'l':'blue', 'o':'orange', 'k':'black', 'f':'none'})\n",
    "df['stem-color'] = df['stem-color'].map({'n':'brown', 'b':'buff', 'g':'gray', 'r':'green', 'p':'pink', 'u':'purple', 'e':'red', 'w':'white', 'y':'yellow', 'l':'blue', 'o':'orange', 'k':'black', 'f':'none'})\n",
    "df['has-ring'] = df['has-ring'].map({'t':'ring', 'f':'none'})\n",
    "df['ring-type'] = df['ring-type'].map({'c':'cobwebby', 'e':'evanescent', 'r':'flaring', 'g':'grooved', 'l':'large', 'p':'pendant', 's':'sheathing', 'z':'zone', 'y':'scaly', 'm':'movable', 'f':'none', '?':'none'})\n",
    "df['habitat'] = df['habitat'].map({'g':'grasses', 'l':'leaves', 'm':'meadows', 'p':'paths', 'h':'heaths', 'u':'urban', 'w':'waste', 'd':'woods'})\n",
    "df['season'] = df['season'].map({'s':'spring', 'u':'summer', 'a':'autumn', 'w':'winter'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(how = 'any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis = px.pie(df, names='label', color='label', color_discrete_sequence=['#008066','#B2D966'], title='Data Distribution')\n",
    "\n",
    "dis.update_traces(textfont_size=18)  \n",
    "dis.update_layout(width=700, height=500, plot_bgcolor='white', paper_bgcolor='white',\n",
    "                  legend=dict(x=0.8, y=1, traceorder='normal', orientation='v', title_font=dict(size=16), font=dict(size=16))\n",
    ")\n",
    "\n",
    "dis.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = df['label'].value_counts()\n",
    "\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.select_dtypes(include=np.number).columns:\n",
    "    \n",
    "    fig = px.box(data_frame=df, x='label', color='label', y=column, color_discrete_sequence=['#B2D966', '#008066'], orientation='v')\n",
    "    fig.update_layout(\n",
    "        width=600,   \n",
    "        height=400,  \n",
    "        plot_bgcolor='white', \n",
    "        paper_bgcolor='white',\n",
    "        title=f'Box plot of {column}', \n",
    "        xaxis_title='Label',\n",
    "        yaxis_title=column,\n",
    "        showlegend=False\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cormat = df.select_dtypes(include=np.number).corr()\n",
    "round(cormat,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cormat, annot=True, cmap='summer', cbar_kws={'shrink': .8}, linewidths=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data=df, hue = 'label', palette=['#B2D966', '#008066'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'label' \n",
    "\n",
    "for column in df.drop(columns=[target_column]).select_dtypes(exclude=[np.number]).columns:\n",
    "\n",
    "    crosstab = pd.crosstab(df[column], df[target_column]).reset_index() # create a contingency table to get the count of each category based on the target\n",
    "\n",
    "    crosstab['total'] = crosstab['e'] + crosstab['p'] # add a column for the total frequencies of each category\n",
    "    crosstab = crosstab.sort_values(by='total', ascending=False)\n",
    "\n",
    "    # melt the DataFrame to long format for easier plotting\n",
    "    crosstab_melted = crosstab.melt(id_vars=[column], value_vars=['e', 'p'], \n",
    "                                    var_name=target_column, value_name='Count')\n",
    "    fig = px.bar(crosstab_melted, \n",
    "                 x=column, \n",
    "                 y='Count', \n",
    "                 color=target_column,\n",
    "                 labels={column: column, 'Count': 'Count', target_column: 'Type'},\n",
    "                 title=f'Frequencies of Edible and Poisonous Fungi for {column}',\n",
    "                 color_discrete_map={'e': '#008066', 'p': '#B2D966'})\n",
    "\n",
    "    fig.update_layout(\n",
    "        width=550,\n",
    "        height=450,\n",
    "        plot_bgcolor='white',\n",
    "        paper_bgcolor='white',\n",
    "        barmode='stack',  \n",
    "        xaxis_title=column,\n",
    "        yaxis_title='Count',\n",
    "        legend=dict(\n",
    "            x=0.9,  \n",
    "            y=0.9,     \n",
    "            title='Type',\n",
    "            traceorder='normal',\n",
    "            orientation='v'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.update_xaxes(categoryorder='total descending')\n",
    "\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cap-diameter'] = round(df['cap-diameter'], 3)\n",
    "df['stem-width'] = round(df['stem-width'], 3)\n",
    "df['stem-height'] = round(df['stem-height'], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cap-diameter'] = pd.to_numeric(df['cap-diameter'], errors='coerce')\n",
    "df['stem-width'] = pd.to_numeric(df['stem-width'], errors='coerce')\n",
    "df['stem-height'] = pd.to_numeric(df['stem-height'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df, test_size):\n",
    "    \n",
    "    if isinstance(test_size, float): # if the test size is a number or if is a proportion(float)\n",
    "        test_size = round(test_size * len(df)) # we have to compute the number of rows this proportion represents\n",
    "\n",
    "    indices = df.index.tolist()\n",
    "    test_indices = random.sample(population = indices, k = test_size) # we want to pick at random a certain number of these indices from this list\n",
    "\n",
    "    test_df = df.loc[test_indices] # we create the test daframe by just indexing our input dataframe\n",
    "    train_df = df.drop(test_indices)\n",
    "    \n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "train_df, test_df = train_test_split(df, test_size = 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_df.values # we transfrom from a pandas df to a numpy 2d array to make everything faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type of feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.columns:\n",
    "    print(column, '-', len(df[column].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_type_of_feature(df):\n",
    "    \n",
    "    feature_types = []\n",
    "    n_unique_values_treshold = 15\n",
    "    \n",
    "    for feature in df.columns:\n",
    "        if feature != \"label\":\n",
    "            unique_values = df[feature].unique()\n",
    "            example_value = unique_values[0] # we initially pick the first value\n",
    "\n",
    "            if (isinstance(example_value, str)) or (len(unique_values) <= n_unique_values_treshold):\n",
    "                feature_types.append(\"categorical\")\n",
    "            else:\n",
    "                feature_types.append(\"continuous\")\n",
    "    \n",
    "    return feature_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_TYPES = determine_type_of_feature(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_TYPES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is the a leaf node pure ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function is used to see if a certain partion of our data contains just one class(so is pure) or not  \n",
    "# this function will return a boolean, so True if is pure and False if it is not\n",
    "# remember that when the data will be unique, so it will be pure, it can be classified directly\n",
    "\n",
    "def check_purity(data):        \n",
    "    \n",
    "    label_column = data[:, -1]\n",
    "    unique_classes = np.unique(label_column) # how many distinct classes are in this array ? we use the numpy function 'unique'\n",
    "\n",
    "    if len(unique_classes) == 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_column = data[:, -1]\n",
    "unique_classes = np.unique(label_column) \n",
    "\n",
    "unique_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_purity(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_purity(train_df[train_df.label == 'e'].values) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_purity(train_df[train_df['cap-diameter'] > 18].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so in this case we want to classify if a data is poisoned or not\n",
    "# we calssify on the base of the majority class that appears \n",
    "\n",
    "def classify_data(data):\n",
    "    \n",
    "    label_column = data[:, -1]\n",
    "    unique_classes, counts_unique_classes = np.unique(label_column, return_counts = True) # which class appears most often ?\n",
    "\n",
    "    index = counts_unique_classes.argmax() # we need to know the index of the largest value of the 'counts_unique_classes' array to see which is the class that appears most often\n",
    "    classification = unique_classes[index]\n",
    "    \n",
    "    return classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_column = data[:, -1]\n",
    "unique_classes, counts_unique_classes = np.unique(label_column, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_classes, counts_unique_classes # in this case we can see that the p class is the one that appears most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = counts_unique_classes.argmax() \n",
    "classification = unique_classes[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification # so p is the label that appears most often, and it is indexed 1, so it is in position 1 in the 'counts_unique_classes' array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_data(train_df[train_df['cap-diameter'] < 10].values) # so considering 'cap-diameter' lower than 10 the p category is the one that appear most "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Potential split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_potential_splits(data): # data which is a 2d numpy array\n",
    "    \n",
    "    potential_splits = {} # dictionary, that has as keys the indeces of the columns and as values the list that contains all the potential splits\n",
    "    _, n_columns = data.shape # tuple that return the number of rows and the number of columns that we have in the dataframe, we only take the number of columns\n",
    "    for column_index in range(n_columns - 1): # excluding the last column which is the label\n",
    "        values = data[:, column_index] # values from a particualar variable(feature) or column\n",
    "        unique_values = np.unique(values) # unique values for that variable\n",
    "        \n",
    "        potential_splits[column_index] = unique_values # for every columns we are going to create an entry in our potential split dictionary, so we are going to append our potential split\n",
    "    \n",
    "    return potential_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_potential_splits(data) # the keys are the indecis of the columns and the values are the rows that contain numbers for the potential split, that are the unique values for every columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "potential_split = get_potential_splits(data)\n",
    "\n",
    "sns.lmplot(data = train_df, x = 'cap-diameter', y = 'stem-width', hue = 'label', fit_reg = False)\n",
    "\n",
    "# plt.vlines(x = potential_split[0], ymin = 0, ymax = 100)\n",
    "# plt.hlines(y = potential_split[8], xmin = 0, xmax = 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(data = train_df, x = 'cap-diameter', y = 'stem-height', hue = 'label', fit_reg = False)\n",
    "\n",
    "# plt.vlines(x = potential_split[0], ymin = 0, ymax = 100)\n",
    "# plt.hlines(y = potential_split[8], xmin = 0, xmax = 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(data = train_df, x = 'cap-diameter', y = 'stem-width', hue = 'label', fit_reg = False)\n",
    "\n",
    "# plt.vlines(x = potential_split[0], ymin = 0, ymax = 100)\n",
    "# plt.hlines(y = potential_split[8], xmin = 0, xmax = 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 parameters regarding at which feature we are going to make the split and the second one is about the value at which we are going to make the split\n",
    "\n",
    "def split_data(data, split_column, split_value): \n",
    "    \n",
    "    split_column_values = data[:, split_column]\n",
    "\n",
    "    type_of_feature = FEATURE_TYPES[split_column]\n",
    "    if type_of_feature == \"continuous\":\n",
    "        data_below = data[split_column_values <= split_value] # data below the split value\n",
    "        data_above = data[split_column_values >  split_value] # data above the split value\n",
    "    \n",
    "    # feature is categorical   \n",
    "    else:\n",
    "        data_below = data[split_column_values == split_value]\n",
    "        data_above = data[split_column_values != split_value]\n",
    "    \n",
    "    return data_below, data_above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example continuos variable\n",
    "\n",
    "split_column = 0\n",
    "split_value = 5\n",
    "\n",
    "split_column_values = data[:, split_column]\n",
    "\n",
    "split_column_values <= split_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example categorical variables \n",
    "\n",
    "split_column = 1\n",
    "split_value == 'b'\n",
    "\n",
    "split_column_values = data[:, split_column]\n",
    "\n",
    "split_column_values == split_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaled entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function should look at all the potential split and then determine the one split that result in the lowest overall entropy\n",
    "\n",
    "def calculate_entropy(data): \n",
    "    \n",
    "    label_column = data[:, -1]\n",
    "    _, counts = np.unique(label_column, return_counts = True)\n",
    "\n",
    "    probabilities = counts / counts.sum()\n",
    "    entropy = sum((- probabilities/2) * np.log2(probabilities + 1e-10) - (1 - probabilities)/2 * np.log2(1 + 1e-10 - probabilities))\n",
    "     \n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, counts = np.unique(label_column, return_counts=True)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = counts / counts.sum()\n",
    "\n",
    "probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_entropy(data) # near to one, so there is a high confunsion between the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_entropy(test_df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_overall_entropy(data_below, data_above): # we will compute the entropy belonging to the below data and to the above data\n",
    "    \n",
    "    n = len(data_below) + len(data_above)\n",
    "    p_data_below = len(data_below) / n\n",
    "    p_data_above = len(data_above) / n\n",
    "\n",
    "    overall_entropy =  (p_data_below * calculate_entropy(data_below) \n",
    "                      + p_data_above * calculate_entropy(data_above))\n",
    "    \n",
    "    return overall_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gini function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gini(data):\n",
    "    \n",
    "    label_column = data[:, -1]\n",
    "    _, counts = np.unique(label_column, return_counts=True)\n",
    "\n",
    "    probabilities = counts / counts.sum()\n",
    "    gini = sum(2*probabilities * (1 - probabilities))\n",
    "     \n",
    "    return gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_gini(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_overall_gini(data_below, data_above):\n",
    "    \n",
    "    n = len(data_below) + len(data_above)\n",
    "    p_data_below = len(data_below) / n\n",
    "    p_data_above = len(data_above) / n\n",
    "\n",
    "    overall_gini =  (p_data_below * calculate_gini(data_below) \n",
    "                    + p_data_above * calculate_gini(data_above))\n",
    "    \n",
    "    return overall_gini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third splitting criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_split_3(data):\n",
    "    \n",
    "    label_column = data[:, -1]\n",
    "    _, counts = np.unique(label_column, return_counts=True)\n",
    "\n",
    "    probabilities = counts / counts.sum()\n",
    "    split_3 = sum(np.sqrt(probabilities * (1 - probabilities)))\n",
    "\n",
    "    return split_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_split_3(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_overall_split_3(data_below, data_above):\n",
    "    \n",
    "    n = len(data_below) + len(data_above)\n",
    "    p_data_below = len(data_below) / n\n",
    "    p_data_above = len(data_above) / n\n",
    "\n",
    "    overall_split_3 = (p_data_below * calculate_split_3(data_below) \n",
    "                      + p_data_above * calculate_split_3(data_above))\n",
    "    \n",
    "    return overall_split_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine best split according to the entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we would like to look at all the potential split and determine the one split that result in the lowest overall entropy \n",
    "\n",
    "def determine_best_split(data, potential_splits):\n",
    "    \n",
    "    overall_entropy = 9999\n",
    "    for column_index in potential_splits: # so this will loop over the keys that are the column indices\n",
    "        for value in potential_splits[column_index]: # this will loop over all the elements of the dictionary\n",
    "            data_below, data_above = split_data(data, split_column=column_index, split_value=value)\n",
    "            current_overall_entropy = calculate_overall_entropy(data_below, data_above)\n",
    "\n",
    "            if current_overall_entropy <= overall_entropy: # is the current overall entropy smaller or equal than the initial overall entropy ? it can be equal because there could be more split that gives back the same cut in the entropy\n",
    "                overall_entropy = current_overall_entropy # if yes we are going to update the overall entropy and we are going to save this values in the 'best_split_column' and 'best_split_value' values\n",
    "                best_split_column = column_index\n",
    "                best_split_value = value\n",
    "    \n",
    "    return best_split_column, best_split_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine best split according to the gini function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_best_split_gini(data, potential_splits):\n",
    "    \n",
    "    overall_gini = 9999\n",
    "    for column_index in potential_splits: \n",
    "        for value in potential_splits[column_index]: \n",
    "            data_below, data_above = split_data(data, split_column=column_index, split_value=value)\n",
    "            current_overall_gini = calculate_overall_gini(data_below, data_above)\n",
    "\n",
    "            if current_overall_gini <= overall_gini:\n",
    "                overall_gini = current_overall_gini \n",
    "                best_split_column = column_index\n",
    "                best_split_value = value\n",
    "    \n",
    "    return best_split_column, best_split_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine best split according to the third split method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_best_split_3(data, potential_splits):\n",
    "    \n",
    "    overall_3 = 9999\n",
    "    for column_index in potential_splits: \n",
    "        for value in potential_splits[column_index]: \n",
    "            data_below, data_above = split_data(data, split_column=column_index, split_value=value)\n",
    "            current_overall_3 = calculate_overall_split_3(data_below, data_above)\n",
    "\n",
    "            if current_overall_3 <= overall_3:\n",
    "                overall_3 = current_overall_3 \n",
    "                best_split_column = column_index\n",
    "                best_split_value = value\n",
    "    \n",
    "    return best_split_column, best_split_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_method(data, potential_splits, criterion='gini'):\n",
    "    if criterion == 'scaled_entropy':\n",
    "        return determine_best_split(data, potential_splits)\n",
    "    elif criterion == 'gini':\n",
    "        return determine_best_split_gini(data, potential_splits)\n",
    "    elif criterion == 'third_method':\n",
    "        return determine_best_split_3(data, potential_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree_algorithm(df, counter = 0, min_samples = 200, max_depth = 5, criterion = 'scaled_entropy'):\n",
    "    \n",
    "    # data preparations\n",
    "    if counter == 0: # so in the first call of the function we give a general information about the data since all the helper function works for a 2d numpy array \n",
    "        global COLUMN_HEADERS, FEATURE_TYPES # we specify these variables as globals\n",
    "        COLUMN_HEADERS = df.columns\n",
    "        FEATURE_TYPES = determine_type_of_feature(df)\n",
    "        data = df.values\n",
    "    else:\n",
    "        data = df           \n",
    "    \n",
    "    \n",
    "    # base cases, where the stopping conditions are presented\n",
    "    # check_purity gives back a boolean array that can be directly be classifies\n",
    "    # also we classify a data if there are not 'min_samples' datapoints, even though it could not be pure yet\n",
    "    # so if in a particular node the number of samples becomes less than the minimum samples then we will not split that node any further and it will be a leaf node\n",
    "    # if the depth of the tree reach the maximum depth we will not split the nodes further\n",
    "    if (check_purity(data)) or (len(data) < min_samples) or (counter == max_depth): \n",
    "        classification = classify_data(data)\n",
    "        \n",
    "        return classification\n",
    "\n",
    "    \n",
    "    # recursive part\n",
    "    else:    \n",
    "        counter += 1\n",
    "\n",
    "        # helper functions \n",
    "        potential_splits = get_potential_splits(data)\n",
    "        split_column, split_value = split_method(data, potential_splits, criterion=criterion)\n",
    "        data_below, data_above = split_data(data, split_column, split_value)\n",
    "        \n",
    "        # check for empty data\n",
    "        if len(data_below) == 0 or len(data_above) == 0:\n",
    "            classification = classify_data(data)\n",
    "            return classification\n",
    "        \n",
    "        # determine question\n",
    "        feature_name = COLUMN_HEADERS[split_column]\n",
    "        type_of_feature = FEATURE_TYPES[split_column]\n",
    "        if type_of_feature == \"continuous\":\n",
    "            question = \"{} <= {}\".format(feature_name, split_value)\n",
    "            \n",
    "        # feature is categorical\n",
    "        else:\n",
    "            question = \"{} = {}\".format(feature_name, split_value)\n",
    "        \n",
    "        # instantiate sub-tree\n",
    "        sub_tree = {question: []} # in that empty list we want to append the yes or no answer \n",
    "        \n",
    "        # find answers (recursion), so we have to re run the algotith in order to get to the classify function \n",
    "        yes_answer = decision_tree_algorithm(data_below, counter, min_samples, max_depth, criterion)\n",
    "        no_answer = decision_tree_algorithm(data_above, counter, min_samples, max_depth, criterion)\n",
    "        \n",
    "        # If the answers are the same, then there is no point in asking the question.\n",
    "        # This could happen when the data is classified even though it is not pure yet (min_samples or max_depth base case).\n",
    "        if yes_answer == no_answer:\n",
    "            sub_tree = yes_answer\n",
    "        else:\n",
    "            sub_tree[question].append(yes_answer)\n",
    "            sub_tree[question].append(no_answer)\n",
    "        \n",
    "        return sub_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_example(example, tree):\n",
    "    question = list(tree.keys())[0]\n",
    "    feature_name, comparison_operator, value = question.split(\" \") # for example feature name is 'stem-width', comparison operator is '<=' and value is '8.85'\n",
    "\n",
    "    # ask question\n",
    "    \n",
    "    # feature is continuous\n",
    "    if comparison_operator == \"<=\":  \n",
    "        if example[feature_name] <= float(value):\n",
    "            answer = tree[question][0] # yes answer\n",
    "        else:\n",
    "            answer = tree[question][1] # no answer\n",
    "    \n",
    "    # feature is categorical\n",
    "    else:\n",
    "        if str(example[feature_name]) == value:\n",
    "            answer = tree[question][0]\n",
    "        else:\n",
    "            answer = tree[question][1]\n",
    "\n",
    "    # base case, so when our answer is not a dictionary, so is not a 'p' or a 'e' but a residual part of the tree\n",
    "    if not isinstance(answer, dict):\n",
    "        return answer\n",
    "    \n",
    "    # recursive part\n",
    "    else:\n",
    "        residual_tree = answer\n",
    "        return classify_example(example, residual_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(df, tree):\n",
    "    \n",
    "    # The syntax args in function definitions is used to pass a variable number of arguments to a function\n",
    "    df[\"classification\"] = df.apply(classify_example, args = (tree,), axis = 1) # this variable will contain the classfification of our examples\n",
    "    df[\"classification_correct\"] = df[\"classification\"] == df[\"label\"]\n",
    "    \n",
    "    accuracy = df[\"classification_correct\"].mean()\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_one_loss(y_true, y_pred):\n",
    "\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    \n",
    "    incorrect_predictions = np.sum(y_true != y_pred)\n",
    "    \n",
    "    loss = incorrect_predictions / len(y_true)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "train_df, test_df = train_test_split(df, test_size = 0.2)\n",
    "\n",
    "tree = decision_tree_algorithm(train_df, min_samples = 500, max_depth = 5, criterion='scaled_entropy')\n",
    "pprint(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification of examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = test_df.iloc[0]\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(tree.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example['stem-width']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example['stem-width'] <= 8.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = list(tree.keys())[0]\n",
    "tree[question][1] # no answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_example(example, tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.loc[38308]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.loc[49293]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = [classify_example(train_df.loc[i], tree) for i in train_df.index]\n",
    "\n",
    "y_pred_test = [classify_example(test_df.loc[i], tree) for i in test_df.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_train = train_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_test = test_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_one_loss(y_true_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_one_loss(y_true_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_accuracy(test_df, tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_accuracy(train_df, tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_true_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['edible', 'poisoned']\n",
    "features = df.columns\n",
    "\n",
    "sns.heatmap(confusion_matrix(y_true_test, y_pred_test),yticklabels=classes,\n",
    "            xticklabels=classes,annot=True,cmap='summer', fmt='g')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.iloc[:, :-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.iloc[:, :-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = {\"max_depth\": [], \"min_samples\": [], \"accuracy_train\": [], \"accuracy_test\": []}\n",
    "\n",
    "for max_depth in range(3, 7):\n",
    "    for min_samples in range(500, 3000, 500):\n",
    "\n",
    "        tree = decision_tree_algorithm(train_df, max_depth=max_depth, min_samples=min_samples, criterion = 'scaled_entropy')\n",
    "\n",
    "        y_true_train = train_df['label'].values\n",
    "        y_true_test = test_df['label'].values\n",
    "\n",
    "        y_pred_train = [classify_example(train_df.loc[i], tree) for i in train_df.index]\n",
    "        y_pred_test = [classify_example(test_df.loc[i], tree) for i in test_df.index]\n",
    "\n",
    "\n",
    "        accuracy_train = accuracy_score(y_true_train, y_pred_train)\n",
    "        accuracy_test = accuracy_score(y_true_test, y_pred_test)\n",
    "\n",
    "        grid_search[\"max_depth\"].append(max_depth)\n",
    "        grid_search[\"min_samples\"].append(min_samples)\n",
    "        grid_search[\"accuracy_train\"].append(accuracy_train)\n",
    "        grid_search[\"accuracy_test\"].append(accuracy_test)\n",
    "        \n",
    "    print(f\"Progress: Iteration max_depth={max_depth}/6\")\n",
    "\n",
    "grid_search_df = pd.DataFrame(grid_search)\n",
    "grid_search_df.sort_values(\"accuracy_test\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "\n",
    "for max_depth in range(1, 25):\n",
    "    \n",
    "    tree = decision_tree_algorithm(train_df, min_samples=500, max_depth=max_depth, criterion = 'scaled_entropy')\n",
    "\n",
    "    y_true_train = train_df['label'].values\n",
    "\n",
    "    \n",
    "    y_true_test = test_df['label'].values\n",
    "\n",
    "    y_pred_train = [classify_example(train_df.loc[i], tree) for i in train_df.index]\n",
    "    y_pred_test = [classify_example(test_df.loc[i], tree) for i in test_df.index]\n",
    "\n",
    "\n",
    "    accuracy_train = accuracy_score(y_true_train, y_pred_train)\n",
    "    accuracy_test = accuracy_score(y_true_test, y_pred_test)\n",
    "\n",
    "    train_accuracies.append(accuracy_train)\n",
    "    test_accuracies.append(accuracy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 5))\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.plot(train_accuracies, label= \"train accuracy\")\n",
    "plt.plot(test_accuracies, label=\"test accuracy\")\n",
    "plt.legend(loc = \"upper left\")\n",
    "plt.xticks(range(0, 26, 5))\n",
    "plt.xlabel(\"max_depth\", size = 15)\n",
    "plt.ylabel(\"accuracy\", size = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2)\n",
    "tree = decision_tree_algorithm(train_df, min_samples = 20, max_depth=5)\n",
    "accuracy = calculate_accuracy(test_df, tree)\n",
    "\n",
    "pprint(tree, width = 50)\n",
    "accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
